{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "638102cb",
   "metadata": {},
   "source": [
    "!pip install --upgrade numpy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a6f80d",
   "metadata": {},
   "source": [
    "# import necessary library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0042f15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ede646",
   "metadata": {},
   "source": [
    "# read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "715292f9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'mxmh_survey_results.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#import data\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmxmh_survey_results.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m df\n",
      "File \u001b[1;32mD:\\anaconda\\Lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\anaconda\\Lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\anaconda\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mD:\\anaconda\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mD:\\anaconda\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32mD:\\anaconda\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1736\u001b[0m     f,\n\u001b[0;32m   1737\u001b[0m     mode,\n\u001b[0;32m   1738\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1739\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1740\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1741\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1742\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1743\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1744\u001b[0m )\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mD:\\anaconda\\Lib\\site-packages\\pandas\\io\\common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    857\u001b[0m             handle,\n\u001b[0;32m    858\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    859\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    860\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    861\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    862\u001b[0m         )\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'mxmh_survey_results.csv'"
     ]
    }
   ],
   "source": [
    "#import data\n",
    "df = pd.read_csv(\"mxmh_survey_results.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62838c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23c7033",
   "metadata": {},
   "source": [
    "# data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5964e627",
   "metadata": {},
   "source": [
    "## checking duplicated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de34b821",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5948b97f",
   "metadata": {},
   "source": [
    "## checking missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce463bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9695ca",
   "metadata": {},
   "source": [
    "There are 7 attributes with missing values which are age, primary streaming service, while working, instrumentalist, composer, exploratory, foreign language, BPM and Music effect. Since the missing value of bpm is too much (more than 1/7 observations) hence instead of treating it we decide to drop it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20554d77",
   "metadata": {},
   "source": [
    "## checking for outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54b0791",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "columns_of_interest = [\"Age\", \"Hours per day\", \"BPM\", \"Anxiety\", \"Depression\", \"Insomnia\", \"OCD\"]\n",
    "\n",
    "# Create a boxplot for each selected column\n",
    "plt.figure(figsize=(12, 8))\n",
    "for column in columns_of_interest:\n",
    "    sns.boxplot(x=df[column])\n",
    "    plt.title(f'Boxplot for {column}')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78767e0",
   "metadata": {},
   "source": [
    "Hours per day exist outlier around 24 hours(1day)which is not reasonable, therefore we need to deal with it.\n",
    "\n",
    "BPM exist extreme value thus need to deal with it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53102200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Distribution Graph\n",
    "sns.distplot(df['BPM'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa5a993",
   "metadata": {},
   "source": [
    "We found that there is an extreme large value(1.000000e+09) exist in BPM, thus we will check for it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0285d6e",
   "metadata": {},
   "source": [
    "## checking for class balancing of response variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843e46c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming class_balance is the result of df['Music effects'].value_counts()\n",
    "class_balance = df['Music effects'].value_counts()\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(8, 6))\n",
    "class_balance.plot(kind='bar', color='skyblue')\n",
    "plt.title('Class Balance for Music Effects')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5494f36c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class_balance = df['Music effects'].value_counts()\n",
    "print(class_balance)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6151b9e3",
   "metadata": {},
   "source": [
    "# Imputation for missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70e4285",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill with mode since categorical data type\n",
    "df['Primary streaming service'] = df['Primary streaming service'].fillna(df['Primary streaming service'].mode()[0])\n",
    "df['While working'] = df['While working'].fillna(df['While working'].mode()[0])\n",
    "df['Instrumentalist'] = df['Instrumentalist'].fillna(df['Instrumentalist'].mode()[0])\n",
    "df['Composer'] = df['Composer'].fillna(df['Composer'].mode()[0])\n",
    "df['Foreign languages'] = df['Foreign languages'].fillna(df['Foreign languages'].mode()[0])\n",
    "df['Music effects'] = df['Music effects'].fillna(df['Music effects'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d97e91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer,SimpleImputer\n",
    "impute = KNNImputer()\n",
    "simple_impute = SimpleImputer(missing_values='NAN', strategy='mean')\n",
    "df['Age'] = impute.fit_transform(df['Age'].values.reshape(-1,1))\n",
    "df['BPM'] = impute.fit_transform(df['BPM'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20d8a92",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c124c60",
   "metadata": {},
   "source": [
    "# Handle extreme value and capping outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24f55d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming 'BPM' is the column you want to analyze in the DataFrame 'df'\n",
    "# Replace 'df' and 'BPM' with your actual DataFrame and column name\n",
    "\n",
    "# Calculate the IQR (Interquartile Range)\n",
    "Q1 = df['BPM'].quantile(0.25)\n",
    "Q3 = df['BPM'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define the lower and upper bounds for outliers\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Identify outliers\n",
    "outliers = df[(df['BPM'] < lower_bound) | (df['BPM'] > upper_bound)]\n",
    "\n",
    "# Display only the 'BPM' column of outliers\n",
    "print(\"BPM column outliers:\")\n",
    "print(outliers['BPM'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11d3d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming 'BPM' is the column you want to modify in the DataFrame 'df'\n",
    "# Replace 'df' and 'BPM' with your actual DataFrame and column name\n",
    "\n",
    "# Calculate the median of the 'BPM' column\n",
    "median_bpm = df['BPM'].median()\n",
    "\n",
    "# Replace extreme values with the median\n",
    "df['BPM'] = df['BPM'].apply(lambda x: median_bpm if x == 999999999 else x)\n",
    "\n",
    "# Calculate the IQR (Interquartile Range) after the initial replacement\n",
    "Q1 = df['BPM'].quantile(0.25)\n",
    "Q3 = df['BPM'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define the lower and upper bounds for capping\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Apply capping to remaining outliers\n",
    "df['BPM'] = df['BPM'].apply(lambda x: upper_bound if x > upper_bound else lower_bound if x < lower_bound else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e2243b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Calculate the IQR (Interquartile Range)\n",
    "Q1 = df['Hours per day'].quantile(0.25)\n",
    "Q3 = df['Hours per day'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define the lower and upper bounds for outliers\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Identify outliers\n",
    "outliers = df[(df['Hours per day'] < lower_bound) | (df['Hours per day'] > upper_bound)]\n",
    "\n",
    "# Display only the 'hours_per_day' column of outliers\n",
    "print(\"Hours per day column outliers:\")\n",
    "print(outliers['Hours per day'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef6810c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Calculate the median of the 'hours_per_day' column\n",
    "median_hours_per_day = df['Hours per day'].median()\n",
    "\n",
    "# Replace extreme values with the median\n",
    "df['Hours per day'] = df['Hours per day'].apply(lambda x: median_hours_per_day if x == 24 else x)\n",
    "\n",
    "# Apply capping to remaining outliers\n",
    "df['Hours per day'] = df['Hours per day'].apply(lambda x: upper_bound if x > upper_bound else lower_bound if x < lower_bound else x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82eceb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Calculate the IQR (Interquartile Range)\n",
    "Q1 = df['Age'].quantile(0.25)\n",
    "Q3 = df['Age'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define the lower and upper bounds for capping\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Apply capping to remaining outliers\n",
    "df['Age'] = df['Age'].apply(lambda x: upper_bound if x > upper_bound else lower_bound if x < lower_bound else x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9ffaf0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming 'data' is your DataFrame\n",
    "columns_of_interest = [\"Age\", \"Hours per day\", \"BPM\", \"Anxiety\", \"Depression\", \"Insomnia\", \"OCD\"]\n",
    "\n",
    "# Create a boxplot for each selected column\n",
    "plt.figure(figsize=(12, 8))\n",
    "for column in columns_of_interest:\n",
    "    sns.boxplot(x=df[column])\n",
    "    plt.title(f'Boxplot for {column}')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954bc7ce",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plotting Distribution Graph\n",
    "sns.distplot(df['BPM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecaec19c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b0eb89",
   "metadata": {},
   "source": [
    "# drop no related column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bef6077",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"Timestamp\",\"Permissions\",\"BPM\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbed2904",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8060233c",
   "metadata": {},
   "outputs": [],
   "source": [
    "genre = df[\"Fav genre\"].value_counts().loc[lambda x: x > 10]\n",
    "total_count = genre.sum()\n",
    "\n",
    "# Calculate percentages\n",
    "percentages = genre / total_count * 100\n",
    "\n",
    "# Plot the pie chart\n",
    "genre.plot(kind='pie', labeldistance=1.2, explode=[0.05, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,],\n",
    "           colors=sns.color_palette('pastel')[0:13], autopct='%1.1f%%')\n",
    "\n",
    "plt.title('Top genre breakdown')\n",
    "plt.ylabel(\"\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868ebc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plt.figure(figsize=(5, 4))\n",
    "plt.title('Effects of Music on Mental Health')\n",
    "\n",
    "effects = df['Music effects'].value_counts()\n",
    "\n",
    "# Calculate percentages\n",
    "total_count = effects.sum()\n",
    "percentages = effects / total_count * 100\n",
    "\n",
    "# Plot the pie chart with percentages\n",
    "effects.plot(kind='pie', colors=[\"indianred\", \"gold\", \"darkblue\"], autopct='%1.1f%%', ylabel='')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a376add",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "m_all = [\"Anxiety\", \"Depression\", \"Insomnia\", \"OCD\"]\n",
    "\n",
    "mental_df = df[m_all]\n",
    "mental_df.round(0).astype(int)\n",
    "\n",
    "disorder_count = []\n",
    "for disorder in m_all:\n",
    "    x=0\n",
    "    while x !=11:\n",
    "        count =  (mental_df[disorder].values == x).sum()\n",
    "        disorder_count.append(count)\n",
    "        x +=1\n",
    "\n",
    "labels = ['0','1', '2', '3', '4', '5', '6', '7', '8', '9', '10']\n",
    "x = np.arange(len(labels))\n",
    "width = 0.15\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(13, 9))\n",
    "\n",
    "b1 = ax.bar(x-2*width, disorder_count[0:11], width, label=\"Anxiety\", color = 'lightpink')\n",
    "b2 = ax.bar(x-width, disorder_count[11:22], width, label=\"Depression\", color = 'cornflowerblue')\n",
    "b3 = ax.bar(x, disorder_count[22:33], width, label=\"Insomnia\", color = 'darkmagenta')\n",
    "b4 = ax.bar(x+width, disorder_count[33:], width, label=\"OCD\", color = 'orange')\n",
    "\n",
    "ax.set_ylim([0, 170])\n",
    "ax.set_ylabel('Number of Rankings')\n",
    "ax.set_xlabel('Ranking')\n",
    "ax.set_title('Mental health ranking distribution')\n",
    "ax.set_xticks(x, labels)\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5766c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "s_colors2 = ['lightgreen', 'darkturquoise', 'lightcoral', 'steelblue', 'palevioletred', 'gold']\n",
    "\n",
    "df.replace(['Other streaming service', 'I do not use a streaming service.', 'YouTube Music'],\n",
    "                       ['Other', 'None', 'YouTube'], inplace=True)\n",
    "\n",
    "bplot = sns.boxplot(data=df, x=\"Primary streaming service\", y = \"Age\",\n",
    "            showfliers = False,\n",
    "            palette = s_colors2)\n",
    "\n",
    "plt.title('Streaming services by Age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5672b047",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "sns.lineplot(x=df['Fav genre'], y=df['Age'], ci=None)\n",
    "plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa40ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "sns.boxplot(x=df['Fav genre'], y=df['Hours per day'])\n",
    "plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358d3678",
   "metadata": {},
   "outputs": [],
   "source": [
    "for disorder in m_all:\n",
    "    d_avg = str(round(df[disorder].mean(), 2))\n",
    "    print(disorder + ' average: ' + d_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f03ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "sns.barplot(x=df['Fav genre'], y=df['Depression'], errwidth=0)\n",
    "plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70af8e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "sns.barplot(x=df['Fav genre'], y=df['Depression'], hue=df['Music effects'], errwidth=0, palette='coolwarm')\n",
    "plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69af9e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "sns.barplot(x=df['Fav genre'], y=df['Insomnia'], errwidth=0)\n",
    "plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b16289f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "sns.barplot(x=df['Fav genre'], y=df['Insomnia'], hue=df['Music effects'], errwidth=0, palette='coolwarm')\n",
    "plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb85041",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "sns.barplot(x=df['Fav genre'], y=df['Anxiety'], errwidth=0)\n",
    "plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b9a209",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "sns.barplot(x=df['Fav genre'], y=df['Anxiety'], hue=df['Music effects'], errwidth=0, palette='coolwarm')\n",
    "plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14c85ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "sns.barplot(x=df['Fav genre'], y=df['OCD'], errwidth=0)\n",
    "plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37f31af",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "sns.barplot(x=df['Fav genre'], y=df['OCD'], hue=df['Music effects'], errwidth=0, palette='coolwarm')\n",
    "plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf4f424",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace(['Video game music'],\n",
    "                       ['Video game'], inplace=True)\n",
    "\n",
    "g_all = df['Fav genre'].unique()\n",
    "g_all.sort()\n",
    "fg_df = df.groupby(['Fav genre'])\n",
    "fg_dist = fg_df['Music effects'].value_counts(ascending=False, normalize=True).tolist()\n",
    "\n",
    "insert_indices = [5, 8, 11, 13, 14, 17, 20, 23, 26, 28, 29, 32, 38]\n",
    "for i in range(len(insert_indices)):\n",
    "    fg_dist.insert(insert_indices[i], 0)\n",
    "\n",
    "imp_dist = fg_dist[0::3]\n",
    "no_eff_dist = fg_dist[1::3]\n",
    "wors_dist = fg_dist[2::3]\n",
    "\n",
    "width = 0.22\n",
    "\n",
    "x = np.arange(len(g_all))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(13, 9))\n",
    "\n",
    "b1 = ax.bar(x-width, imp_dist, width, label=\"Improve\", color = 'indianred')\n",
    "b2 = ax.bar(x, no_eff_dist, width, label=\"No effect\", color = 'gold')\n",
    "b3 = ax.bar(x+width, wors_dist, width, label=\"Worsen\", color = 'darkblue')\n",
    "\n",
    "plt.title(\"Music effects by Favorite Genre\")\n",
    "ax.set_ylabel('Distribution')\n",
    "ax.set_xlabel('Genre')\n",
    "ax.set_xticks(x, g_all, rotation = 45)\n",
    "ax.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b31c042",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be1a95b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b93ce7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ce302c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3b6691",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6616cb2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3fbef9f4",
   "metadata": {},
   "source": [
    "# library for modelling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfcadcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install category_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d18cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f4cea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "import category_encoders as ce\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8456f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bc0616",
   "metadata": {},
   "source": [
    "# Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c38345b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming df is your DataFrame and 'Music effects' is the column with categorical labels\n",
    "le = LabelEncoder()\n",
    "df['Music effects'] = le.fit_transform(df['Music effects'])\n",
    "\n",
    "# Access the mapping\n",
    "label_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "\n",
    "# Print the mapping\n",
    "print(\"Label Mapping:\")\n",
    "print(label_mapping)\n",
    "\n",
    "original_labels = le.inverse_transform([0, 1, 2])\n",
    "print(\"Original Labels:\")\n",
    "print(original_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd6ab7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_values_service = df['Primary streaming service'].unique()\n",
    "unique_values_service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c93368",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_values_genre = df['Fav genre'].unique()\n",
    "unique_values_genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e034fc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_values_frequency= df['Frequency [R&B]'].unique()\n",
    "unique_values_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab9c2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping for categorical variables\n",
    "service_mapping = {\"Spotify\": 0, \"Pandora\": 1, \"YouTube\": 2, \"Apple Music\": 3, \"Other\": 4, \"None\": 5}\n",
    "binary_mapping = {\"Yes\": 1, \"No\": 0}\n",
    "genre_mapping = {\"Classical\": 0, \"Country\": 1, \"EDM\": 2, \"Folk\": 3, \"Gospel\": 4, \"Hip hop\": 5, \"Jazz\": 6, \"K pop\": 7,\n",
    "                 \"Latin\": 8, \"Lofi\": 9, \"Metal\": 10, \"Pop\": 11, \"R&B\": 12, \"Rap\": 13, \"Rock\": 14, \"Video game\": 15}\n",
    "frequency_mapping = {\"Never\": 0, \"Rarely\": 1, \"Sometimes\": 2, \"Very frequently\": 3}\n",
    "\n",
    "\n",
    "# Mapping for specific columns\n",
    "column_mappings = {\n",
    "    \"Primary streaming service\": service_mapping,\n",
    "    \"While working\": binary_mapping,\n",
    "    \"Instrumentalist\": binary_mapping,\n",
    "    \"Composer\": binary_mapping,\n",
    "    \"Exploratory\": binary_mapping,\n",
    "    \"Foreign languages\": binary_mapping,\n",
    "    \"Fav genre\": genre_mapping,\n",
    "    \"Frequency [Classical]\": frequency_mapping,\n",
    "    \"Frequency [Country]\": frequency_mapping,\n",
    "    \"Frequency [EDM]\": frequency_mapping,\n",
    "    \"Frequency [Folk]\": frequency_mapping,\n",
    "    \"Frequency [Gospel]\": frequency_mapping,\n",
    "    \"Frequency [Hip hop]\": frequency_mapping,\n",
    "    \"Frequency [Jazz]\": frequency_mapping,\n",
    "    \"Frequency [K pop]\": frequency_mapping,\n",
    "    \"Frequency [Latin]\": frequency_mapping,\n",
    "    \"Frequency [Lofi]\": frequency_mapping,\n",
    "    \"Frequency [Metal]\": frequency_mapping,\n",
    "    \"Frequency [Pop]\": frequency_mapping,\n",
    "    \"Frequency [R&B]\": frequency_mapping,\n",
    "    \"Frequency [Rap]\": frequency_mapping,\n",
    "    \"Frequency [Rock]\": frequency_mapping,\n",
    "    \"Frequency [Video game music]\": frequency_mapping,\n",
    " \n",
    "}\n",
    "\n",
    "# Apply mappings to the dataset\n",
    "df = df.replace(column_mappings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145a23a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5a3515",
   "metadata": {},
   "source": [
    "# determine the variable that we want to investigate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47173a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664c1cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f96f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['Music effects'], axis=1)\n",
    "y = df['Music effects']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e071a32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Apply SMOTE to solve imbalancing data\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1494b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split your data into training and testing sets (assuming X and y are defined)\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X_resampled,y_resampled,test_size=0.30,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a44522",
   "metadata": {},
   "source": [
    "## determine need to scaling or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d517c692",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f63299",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13ecaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install lazypredict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98c1509",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lazypredict.Supervised import LazyClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca21e015",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "clf = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n",
    "models,predictions = clf.fit(X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "\n",
    "print(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cc6a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import RidgeClassifier, LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3ef4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee015b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85a6fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_classifier_best = LGBMClassifier(random_state=42)\n",
    "\n",
    "\n",
    "# Train the model\n",
    "lgbm_classifier_best.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_lgbm = lgbm_classifier_best.predict(X_test_scaled)\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_lgbm = accuracy_score(y_test, y_pred_lgbm)\n",
    "print(f\"Accuracy for LightGBM Classifier: {accuracy_lgbm:.2f}\")\n",
    "\n",
    "\n",
    "precision_lgbm = precision_score(y_test, y_pred_lgbm,average='weighted')\n",
    "recall_lgbm = recall_score(y_test, y_pred_lgbm,average='weighted')\n",
    "f1_lgbm = f1_score(y_test, y_pred_lgbm,average='weighted')\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report for LightGBM Classifier:\")\n",
    "print(classification_report(y_test, y_pred_lgbm))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76e4107",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Initialize the XGBoost Classifier\n",
    "xgb_classifier = xgb.XGBClassifier(random_state=42)\n",
    "\n",
    "# Define the parameter grid to search\n",
    "param_grid_xgb = {\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'n_estimators': [50, 100, 150],\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search_xgb = GridSearchCV(estimator=xgb_classifier, param_grid=param_grid_xgb, cv=3, scoring='accuracy')\n",
    "\n",
    "# Perform GridSearchCV on the training data\n",
    "grid_search_xgb.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best parameters and model\n",
    "best_params_xgb = grid_search_xgb.best_params_\n",
    "print(\"Best Parameters for XGBoost Classifier:\", best_params_xgb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1159523b",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_classifier_best = xgb.XGBClassifier(learning_rate=0.2, max_depth=7, n_estimators=150,random_state=42)\n",
    "\n",
    "xgb_classifier_best.fit(X_train_scaled, y_train)\n",
    "# Make predictions on the test set using the best model\n",
    "y_pred_xgb = xgb_classifier_best.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the best model\n",
    "accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "print(f\"Best Model Accuracy for XGBoost Classifier: {accuracy_xgb:.2f}\")\n",
    "\n",
    "precision_xgb = precision_score(y_test, y_pred_xgb,average='weighted')\n",
    "recall_xgb = recall_score(y_test, y_pred_xgb,average='weighted')\n",
    "f1_xgb = f1_score(y_test, y_pred_xgb,average='weighted')\n",
    "\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report for XGBoost Classifier:\")\n",
    "print(classification_report(y_test, y_pred_xgb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6e1eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "# Initialize the Extra Trees Classifier\n",
    "et_classifier = ExtraTreesClassifier(random_state=42)\n",
    "\n",
    "param_grid_et = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "grid_search_et = GridSearchCV(estimator=et_classifier, param_grid=param_grid_et, cv=3, scoring='accuracy')\n",
    "grid_search_et.fit(X_train_scaled, y_train)\n",
    "\n",
    "best_params_et = grid_search_et.best_params_\n",
    "print(\"Best Parameters for Extra Trees Classifier:\", best_params_et)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a09c7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "et_classifier_best = ExtraTreesClassifier(max_depth=20, min_samples_leaf=1, min_samples_split= 2, n_estimators=150, random_state=42)\n",
    "\n",
    "et_classifier_best.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the test set using the best model\n",
    "y_pred_et = et_classifier_best.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the best model\n",
    "accuracy_et = accuracy_score(y_test, y_pred_et)\n",
    "print(f\"Best Model Accuracy for Extra Trees Classifier: {accuracy_et:.2f}\")\n",
    "\n",
    "precision_et = precision_score(y_test, y_pred_et,average='weighted')\n",
    "recall_et = recall_score(y_test, y_pred_et,average='weighted')\n",
    "f1_et = f1_score(y_test, y_pred_et,average='weighted')\n",
    "\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report for Extra Trees Classifier:\")\n",
    "print(classification_report(y_test, y_pred_et))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23cc658",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Define the parameter grid to search\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Initialize RandomForestClassifier\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search_rf = GridSearchCV(estimator=rf_classifier, param_grid=param_grid_rf, cv=3, scoring='accuracy')\n",
    "\n",
    "# Perform GridSearchCV on the training data\n",
    "grid_search_rf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best parameters and model\n",
    "best_params_rf = grid_search_rf.best_params_\n",
    "print(\"Best Parameters for Random Forest Classifier:\", best_params_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7d3040",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier_best = RandomForestClassifier(max_depth=20, max_features='log2', min_samples_leaf=1, min_samples_split=2, n_estimators=150,random_state=42)\n",
    "#rf_classifier_best = RandomForestClassifier(max_depth=None, max_features='log2', min_samples_leaf=1, min_samples_split=2, n_estimators=100,random_state=42)\n",
    "# Train the model\n",
    "rf_classifier_best.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_rf = rf_classifier_best.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the best model\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(f\"Best Model Accuracy for Random Forest Classifier: {accuracy_rf:.2f}\")\n",
    "\n",
    "precision_rf  = precision_score(y_test, y_pred_rf,average='weighted')\n",
    "recall_rf  = recall_score(y_test, y_pred_rf,average='weighted')\n",
    "f1_rf  = f1_score(y_test, y_pred_rf,average='weighted')\n",
    "\n",
    "\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report for Random Forest Classifier:\")\n",
    "print(classification_report(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46817623",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "param_grid_svc = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf', 'poly'],\n",
    "    'gamma': ['scale', 'auto'],\n",
    "    'degree': [2, 3, 4]\n",
    "}\n",
    "\n",
    "# Initialize SVC\n",
    "svc_classifier = SVC(random_state=42)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search_svc = GridSearchCV(estimator=svc_classifier, param_grid=param_grid_svc, cv=3, scoring='accuracy')\n",
    "\n",
    "# Perform GridSearchCV on the training data\n",
    "grid_search_svc.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best parameters \n",
    "best_params_svc = grid_search_svc.best_params_\n",
    "print(\"Best Parameters for SVC:\", best_params_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8da3a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_classifier_best = SVC(C=10, degree=2, gamma='scale', kernel='rbf',random_state=42)\n",
    "\n",
    "# Train the model\n",
    "svc_classifier_best.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_svc = svc_classifier_best.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the best model\n",
    "accuracy_svc = accuracy_score(y_test, y_pred_svc)\n",
    "print(f\"Best Model Accuracy for SVC: {accuracy_svc:.2f}\")\n",
    "\n",
    "precision_svc  = precision_score(y_test, y_pred_svc,average='weighted')\n",
    "recall_svc  = recall_score(y_test, y_pred_svc, average='weighted')\n",
    "f1_svc  = f1_score(y_test, y_pred_svc, average='weighted')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report for SVC:\")\n",
    "print(classification_report(y_test, y_pred_svc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93302f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "models = [\n",
    "    'LightGBM Classifier',\n",
    "    'XGBoost Classifier',\n",
    "    'Extra Trees Classifier',\n",
    "    'Random Forest Classifier',\n",
    "    'SVC'\n",
    "]\n",
    "\n",
    "accuracy_scores = [\n",
    "    accuracy_lgbm,\n",
    "    accuracy_xgb,\n",
    "    accuracy_et,\n",
    "    accuracy_rf,\n",
    "    accuracy_svc\n",
    "]\n",
    "\n",
    "precision_scores = [\n",
    "    precision_lgbm,\n",
    "    precision_xgb,\n",
    "    precision_et,\n",
    "    precision_rf,\n",
    "    precision_svc\n",
    "]\n",
    "\n",
    "recall_scores = [\n",
    "    recall_lgbm,\n",
    "    recall_xgb,\n",
    "    recall_et,\n",
    "    recall_rf,\n",
    "    recall_svc\n",
    "]\n",
    "\n",
    "f1_scores = [\n",
    "    f1_lgbm,\n",
    "    f1_xgb,\n",
    "    f1_et,\n",
    "    f1_rf,\n",
    "    f1_svc\n",
    "]\n",
    "\n",
    "# Create a DataFrame\n",
    "results_df = pd.DataFrame({\n",
    "    'Model Name': models,\n",
    "    'Accuracy': accuracy_scores,\n",
    "    'Precision': precision_scores,\n",
    "    'Recall': recall_scores,\n",
    "    'F1': f1_scores\n",
    "})\n",
    "\n",
    "# Set the display precision to 4 decimal places\n",
    "pd.set_option('display.float_format', '{:.4f}'.format)\n",
    "\n",
    "# Sort the DataFrame by 'Accuracy' in descending order\n",
    "results_df = results_df.sort_values(by='Accuracy', ascending=False)\n",
    "\n",
    "# Set the 'Model Name' column as the index\n",
    "results_df = results_df.set_index('Model Name')\n",
    "\n",
    "# Print the sorted and formatted results DataFrame\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261779ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have already trained your LightGBM model (lgbm_classifier)\n",
    "# If not, use the previous code to train your model\n",
    "\n",
    "# Plot feature importance\n",
    "lgb.plot_importance(lgbm_classifier_best, max_num_features=10, figsize=(10, 6), importance_type='split')\n",
    "plt.title('Feature Importance - Split')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe714805",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "lgb.plot_tree(lgbm_classifier_best, tree_index=0, figsize=(20, 10), show_info=['split_gain'])\n",
    "plt.title('LightGBM Decision Tree Structure')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f593e2b",
   "metadata": {},
   "source": [
    "While working, Instrumentalist, Composer, Exploratory,\tForeign languages : \\\n",
    "\"Yes\": 1, \"No\": 0\n",
    "\n",
    "Fav genre：\\\n",
    "\"Classical\": 0, \"Country\": 1, \"EDM\": 2, \"Folk\": 3, \"Gospel\": 4, \"Hip hop\": 5, \"Jazz\": 6, \"K pop\": 7, \"Latin\": 8, \"Lofi\": 9, \"Metal\": 10, \"Pop\": 11, \"R&B\": 12, \"Rap\": 13, \"Rock\": 14, \"Video game music\": 15\n",
    "\n",
    "Frequency [Classical] , Frequency [Country], Frequency [EDM], Frequency [Folk], Frequency [Gospel], Frequency [Hip hop], Frequency [Jazz], Frequency [K pop], Frequency [Latin], Frequency [Lofi], Frequency [Metal], Frequency [Pop], Frequency [R&B], Frequency [Rap], Frequency [Rock], Frequency [Video game music] : \\\n",
    "\"Never\": 0, \"Rarely\": 1, \"Sometimes\": 2, \"Very frequently\": 3 \n",
    "\n",
    "Primary streaming service :\\\n",
    "\"Spotify\": 0, \"Pandora\": 1, \"YouTube Music\": 2, \"Apple Music\": 3, \"Other streaming service\": 4, \"I do not use a streaming service.\": 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b04cb3d",
   "metadata": {},
   "source": [
    "### Extra Trees Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3b42ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "class ExtraTreesGUI:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"Extra Trees Model GUI\")\n",
    "\n",
    "        # Load your dataset and preprocess it\n",
    "        # Replace this with your actual dataset loading code\n",
    "        # ...\n",
    "\n",
    "        # Preprocess the dataset\n",
    "        # ...\n",
    "\n",
    "        # Convert non-numeric columns to numeric using Label Encoding\n",
    "        label_encoder = LabelEncoder()\n",
    "        for column in df.columns:\n",
    "            if df[column].dtype == 'object':\n",
    "                df[column] = label_encoder.fit_transform(df[column].astype(str))\n",
    "\n",
    "        # Split the data into features and target variable\n",
    "        X = df.drop('Music effects', axis=1)\n",
    "        y = df['Music effects']\n",
    "\n",
    "        # Apply SMOTE to handle class imbalance\n",
    "        smote = SMOTE(random_state=42)\n",
    "        X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "        # Split the resampled data into training and testing sets\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "        # Create and train the Extra Trees model\n",
    "        self.model = ExtraTreesClassifier(n_estimators=150, max_depth=20, min_samples_leaf=1, min_samples_split=2, random_state=42)\n",
    "        self.model.fit(self.X_train, self.y_train)\n",
    "\n",
    "        # Create GUI components\n",
    "        self.create_gui()\n",
    "\n",
    "    def create_gui(self):\n",
    "        # Create a canvas widget and a vertical scrollbar\n",
    "        canvas = tk.Canvas(self.root)\n",
    "        scrollbar = tk.Scrollbar(self.root, orient=\"vertical\", command=canvas.yview)\n",
    "        # Create a frame inside the canvas and attach the scrollbar to the canvas\n",
    "        scrollable_frame = tk.Frame(canvas)\n",
    "        canvas.create_window((0, 0), window=scrollable_frame, anchor=\"nw\")\n",
    "        canvas.configure(yscrollcommand=scrollbar.set)\n",
    "        # Bind the configure event of the canvas to a function that updates the scroll region\n",
    "        canvas.bind(\"<Configure>\", lambda e: canvas.configure(scrollregion=canvas.bbox(\"all\")))\n",
    "        # Pack the canvas and the scrollbar\n",
    "        canvas.pack(side=\"left\", fill=\"both\", expand=True)\n",
    "        scrollbar.pack(side=\"right\", fill=\"y\")\n",
    "\n",
    "        # Create entry fields for each feature in the scrollable frame\n",
    "        for column in self.X_train.columns:\n",
    "            frame = tk.Frame(scrollable_frame)\n",
    "            frame.pack(side=\"top\", fill=\"x\", padx=10, pady=5)\n",
    "\n",
    "            label = tk.Label(frame, text=column)\n",
    "            label.pack(side=\"left\")\n",
    "\n",
    "            entry = tk.Entry(frame)\n",
    "            entry.pack(side=\"left\", padx=5)\n",
    "\n",
    "            # Save entry in an instance variable for later access\n",
    "            setattr(self, f\"{column}_entry\", entry)\n",
    "\n",
    "        # Create predict button in the scrollable frame\n",
    "        self.predict_button = tk.Button(scrollable_frame, text=\"Predict\", command=self.predict)\n",
    "        self.predict_button.pack(pady=10)\n",
    "\n",
    "        # Result label in the scrollable frame\n",
    "        self.result_label = tk.Label(scrollable_frame, text=\"\")\n",
    "        self.result_label.pack()\n",
    "\n",
    "    def predict(self):\n",
    "        # Get user input from entry fields\n",
    "        user_input = [float(getattr(self, f\"{column}_entry\").get()) for column in self.X_train.columns]\n",
    "\n",
    "        # Make predictions using the trained model\n",
    "        prediction = self.model.predict([user_input])[0]\n",
    "\n",
    "        # Display the prediction\n",
    "        self.result_label.config(text=f\"The predicted music effect is: {prediction}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    root = tk.Tk()\n",
    "    app = ExtraTreesGUI(root)\n",
    "    root.mainloop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff619f42",
   "metadata": {},
   "source": [
    "Label Mapping:\n",
    "{'Improve': 0, 'No effect': 1, 'Worsen': 2}\n",
    "Original Labels:\n",
    "['Improve' 'No effect' 'Worsen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2a05af",
   "metadata": {},
   "outputs": [],
   "source": [
    "et_classifier_best = ExtraTreesClassifier(max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=150, random_state=42)\n",
    "et_classifier_best.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the test set using the best model\n",
    "y_pred_et = et_classifier_best.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the best model\n",
    "accuracy_et = accuracy_score(y_test, y_pred_et)\n",
    "print(f\"Best Model Accuracy for Extra Trees Classifier: {accuracy_et:.2f}\")\n",
    "\n",
    "precision_et = precision_score(y_test, y_pred_et, average='weighted')\n",
    "recall_et = recall_score(y_test, y_pred_et, average='weighted')\n",
    "f1_et = f1_score(y_test, y_pred_et, average='weighted')\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report for Extra Trees Classifier:\")\n",
    "print(classification_report(y_test, y_pred_et))\n",
    "\n",
    "# Plotting feature importances as a vertical bar chart\n",
    "feature_importances = pd.Series(et_classifier_best.feature_importances_, index=df.drop('Music effects', axis=1).columns)\n",
    "sorted_importances = feature_importances.sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sorted_importances.plot(kind='barh')\n",
    "plt.title('Feature Importances')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Features')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
